# mlpp-lib

Collection of methods for ML-based postprocessing of weather forecasts.

:warning: **The code in this repository is currently work-in-progress and not recommended for production use.** :warning:



# Quickstart


```python
import numpy as np 
import xarray as xr 
import pandas as pd

from mlpp_lib.datasets import DataModule, DataSplitter
```


```python
LEADTIMES = np.arange(24)
REFTIMES = pd.date_range("2018-01-01", "2018-03-31", freq="24h")
STATIONS = [chr(i) * 3 for i in range(ord("A"), ord("Z"))]
SHAPE = (len(REFTIMES), len(LEADTIMES), len(STATIONS))
DIMS = ["forecast_reference_time", "lead_time", "station"]

def features_dataset() -> xr.Dataset:
    rng = np.random.default_rng(1)
    X = rng.standard_normal(size=(*SHAPE, 4))
    X[(X > 4.5) | (X < -4.5)] = np.nan

    features = xr.Dataset(
        {
            "coe:x1": (DIMS, X[..., 0]),
            "coe:x2": (DIMS, X[..., 1]),
            "obs:x3": (DIMS, X[..., 2]),
            "dem:x4": (DIMS, X[..., 3]),
        },
        coords={
            "forecast_reference_time": REFTIMES,
            "lead_time": LEADTIMES,
            "station": STATIONS,
        },
    )

    return features

def targets_dataset() -> xr.Dataset:
    """
    Create a dataset as if it was loaded from `targets.zarr`.
    """
    rng = np.random.default_rng(1)
    Y = rng.standard_normal(size=(*SHAPE, 2))
    Y[(Y > 4.5) | (Y < -4.5)] = np.nan

    targets = xr.Dataset(
        {"obs:y1": (DIMS, Y[..., 0]), "obs:y2": (DIMS, Y[..., 1])},
        coords={
            "forecast_reference_time": REFTIMES,
            "lead_time": LEADTIMES,
            "station": STATIONS,
        },
    )

    return targets


```

MLPP expects xarray objects that look like this:


```python
features = features_dataset()
print(features)

```

    <xarray.Dataset> Size: 2MB
    Dimensions:                  (forecast_reference_time: 90, lead_time: 24,
                                  station: 25)
    Coordinates:
      * forecast_reference_time  (forecast_reference_time) datetime64[ns] 720B 20...
      * lead_time                (lead_time) int64 192B 0 1 2 3 4 ... 19 20 21 22 23
      * station                  (station) <U3 300B 'AAA' 'BBB' ... 'XXX' 'YYY'
    Data variables:
        coe:x1                   (forecast_reference_time, lead_time, station) float64 432kB ...
        coe:x2                   (forecast_reference_time, lead_time, station) float64 432kB ...
        obs:x3                   (forecast_reference_time, lead_time, station) float64 432kB ...
        dem:x4                   (forecast_reference_time, lead_time, station) float64 432kB ...



```python
targets = targets_dataset()
print(targets)
```

    <xarray.Dataset> Size: 865kB
    Dimensions:                  (forecast_reference_time: 90, lead_time: 24,
                                  station: 25)
    Coordinates:
      * forecast_reference_time  (forecast_reference_time) datetime64[ns] 720B 20...
      * lead_time                (lead_time) int64 192B 0 1 2 3 4 ... 19 20 21 22 23
      * station                  (station) <U3 300B 'AAA' 'BBB' ... 'XXX' 'YYY'
    Data variables:
        obs:y1                   (forecast_reference_time, lead_time, station) float64 432kB ...
        obs:y2                   (forecast_reference_time, lead_time, station) float64 432kB ...


## Preparing data

The entire data processing can be handled by the `DataModule` class: 
- loading the raw data
- train, val, test splits
- normalization
- reshaping to a tensor


```python
splitter = DataSplitter(
    time_split={"train": 0.6, "val": 0.2, "test": 0.2},
    station_split={"train": 0.7, "val": 0.1, "test": 0.2},
    time_split_method="sequential",
    station_split_method="random",
)

datamodule = DataModule(
    features, targets[["obs:y1"]],
    batch_dims=["forecast_reference_time", "lead_time", "station"],
    splitter=splitter
)

datamodule.setup(stage=None)
```

    No normalizer found, data are standardized by default.


## Training
The library builds on top of PyTorch + Keras3 API and provides some useful methods to quickly build probabilistic models, while integrating probabilistic metrics thanks to `scoringrules`. Of course, you're free to use torch and torch distributions to build your own custom model. MLPP won't get in your way!

In the following example the model consists of a fully connected layer and a probabilistic layer modelling a normal distribution parametrized by some predicted parameters, which can either be optimized via a closed form CRPS or a sample-based CRPS.

For sample-based losses, the underlying distribution needs to have a reparametrized sampling function. If that was not available, `SampleLossWrapper` will let you know.


```python
from mlpp_lib.layers import FullyConnectedLayer
from mlpp_lib.models import ProbabilisticModel
from mlpp_lib.losses import DistributionLossWrapper, SampleLossWrapper
from mlpp_lib.probabilistic_layers import BaseDistributionLayer, UniveriateGaussianModule
import scoringrules as sr
import keras


encoder = FullyConnectedLayer(hidden_layers=[16,8], 
                                batchnorm=False, 
                                skip_connection=False,
                                dropout=0.1,
                                mc_dropout=False,
                                activations='sigmoid')
prob_layer = BaseDistributionLayer(distribution=UniveriateGaussianModule())

model = ProbabilisticModel(encoder_layer=encoder, probabilistic_layer=prob_layer)

# crps_normal = DistributionLossWrapper(fn=sr.crps_normal) # closed form CRPS
crps_normal = SampleLossWrapper(fn=sr.crps_ensemble, num_samples=100) # sample-based CRPS 

model.compile(loss=crps_normal, optimizer=keras.optimizers.Adam(learning_rate=0.1))

history = model.fit(
    datamodule.train.x, datamodule.train.y,
    epochs = 2,
    batch_size = 32,
    validation_data = (datamodule.val.x, datamodule.val.y)
)
```

    Epoch 1/2


    [1m  1/689[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4:50[0m 422ms/step - loss: 0.6066

    [1m 11/689[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 5ms/step - loss: 0.6295    

    [1m 21/689[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 5ms/step - loss: 0.6069

    [1m 31/689[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 5ms/step - loss: 0.5980

    [1m 41/689[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 5ms/step - loss: 0.5929

    [1m 51/689[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 5ms/step - loss: 0.5902

    [1m 61/689[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 5ms/step - loss: 0.5875

    [1m 71/689[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 5ms/step - loss: 0.5852

    [1m 81/689[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 5ms/step - loss: 0.5834

    [1m 91/689[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 5ms/step - loss: 0.5821

    [1m101/689[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 5ms/step - loss: 0.5810

    [1m111/689[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5798

    [1m121/689[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5790

    [1m131/689[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5785

    [1m141/689[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5781

    [1m151/689[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5777

    [1m161/689[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5773

    [1m171/689[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5769

    [1m181/689[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5765

    [1m191/689[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5762

    [1m201/689[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5759

    [1m211/689[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5755

    [1m221/689[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5752

    [1m232/689[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5749

    [1m242/689[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5747

    [1m253/689[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5745

    [1m263/689[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5743

    [1m273/689[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5742

    [1m283/689[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5741

    [1m293/689[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5740

    [1m303/689[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5739

    [1m313/689[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5737

    [1m323/689[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5736

    [1m333/689[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5734

    [1m343/689[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5733

    [1m353/689[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5732

    [1m363/689[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5731

    [1m373/689[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5730

    [1m383/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5729

    [1m393/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5728

    [1m403/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5727

    [1m413/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5727

    [1m423/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5726

    [1m434/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5725

    [1m446/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5724

    [1m458/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5724

    [1m470/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5723

    [1m482/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m1s[0m 5ms/step - loss: 0.5722

    [1m494/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 5ms/step - loss: 0.5721

    [1m506/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 5ms/step - loss: 0.5721

    [1m518/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 5ms/step - loss: 0.5720

    [1m530/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 5ms/step - loss: 0.5719

    [1m542/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 5ms/step - loss: 0.5718

    [1m554/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 5ms/step - loss: 0.5716

    [1m566/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 5ms/step - loss: 0.5715

    [1m578/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 5ms/step - loss: 0.5714

    [1m590/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 5ms/step - loss: 0.5713

    [1m602/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 5ms/step - loss: 0.5712

    [1m614/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 5ms/step - loss: 0.5711

    [1m626/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 5ms/step - loss: 0.5710

    [1m638/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 5ms/step - loss: 0.5709

    [1m650/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 5ms/step - loss: 0.5708

    [1m662/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 5ms/step - loss: 0.5707

    [1m674/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 5ms/step - loss: 0.5706

    [1m686/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 5ms/step - loss: 0.5705

    [1m689/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m4s[0m 5ms/step - loss: 0.5704 - val_loss: 0.5486


    Epoch 2/2


    [1m  1/689[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 6ms/step - loss: 0.6360

    [1m 13/689[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5737

    [1m 24/689[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 5ms/step - loss: 0.5670

    [1m 36/689[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5608

    [1m 48/689[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5577

    [1m 60/689[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5564

    [1m 72/689[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5559

    [1m 84/689[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5555

    [1m 96/689[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5547

    [1m108/689[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5543

    [1m120/689[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5543

    [1m132/689[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5546

    [1m144/689[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5550

    [1m156/689[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5554

    [1m168/689[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5559

    [1m180/689[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5565

    [1m192/689[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5571

    [1m204/689[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5576

    [1m216/689[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5580

    [1m228/689[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 4ms/step - loss: 0.5584

    [1m240/689[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5587

    [1m252/689[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5589

    [1m264/689[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5592

    [1m276/689[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5595

    [1m288/689[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5597

    [1m300/689[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5599

    [1m312/689[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5600

    [1m324/689[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5601

    [1m336/689[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5602

    [1m348/689[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5603

    [1m360/689[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5604

    [1m372/689[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5605

    [1m384/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5605

    [1m396/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5606

    [1m408/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5606

    [1m420/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5607

    [1m432/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5607

    [1m444/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5608

    [1m456/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m1s[0m 4ms/step - loss: 0.5608

    [1m468/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5609

    [1m480/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5609

    [1m492/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5610

    [1m504/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5611

    [1m516/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5611

    [1m528/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5612

    [1m540/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5613

    [1m552/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5613

    [1m564/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5614

    [1m576/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5615

    [1m588/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5615

    [1m600/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5616

    [1m612/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 4ms/step - loss: 0.5617

    [1m624/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 4ms/step - loss: 0.5617

    [1m636/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 4ms/step - loss: 0.5617

    [1m648/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 4ms/step - loss: 0.5618

    [1m660/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 4ms/step - loss: 0.5618

    [1m672/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 4ms/step - loss: 0.5619

    [1m684/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 4ms/step - loss: 0.5619

    [1m689/689[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 5ms/step - loss: 0.5619 - val_loss: 0.5535


## Predictions
Once your model is trained, you can make predictions and create ensembles by sampling from the predictive distribution. The `Dataset` class comes with a method to wrap your ensemble predictions in a xarray object with the correct dimensions and coordinates.


```python
test_pred_ensemble = model(datamodule.test.x).sample(21)
test_pred_ensemble = datamodule.test.dataset_from_predictions(test_pred_ensemble, ensemble_axis=0)
print(test_pred_ensemble)
```

    <xarray.Dataset> Size: 363kB
    Dimensions:                  (realization: 21, forecast_reference_time: 18,
                                  lead_time: 24, station: 5)
    Coordinates:
      * forecast_reference_time  (forecast_reference_time) datetime64[ns] 144B 20...
      * lead_time                (lead_time) int64 192B 0 1 2 3 4 ... 19 20 21 22 23
      * station                  (station) <U3 60B 'AAA' 'III' 'NNN' 'VVV' 'YYY'
      * realization              (realization) int64 168B 0 1 2 3 4 ... 17 18 19 20
    Data variables:
        obs:y1                   (realization, forecast_reference_time, lead_time, station) float64 363kB ...


## Build the README

```
poetry run jupyter nbconvert --execute --to markdown README.ipynb
```
